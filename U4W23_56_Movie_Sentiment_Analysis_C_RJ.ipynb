{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahulJuluru2/unit4assignments/blob/main/U4W23_56_Movie_Sentiment_Analysis_C_RJ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i35LuPCsxJaQ"
      },
      "source": [
        "\n",
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9wLqIUIyML-"
      },
      "source": [
        "## Learning Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD86AWh0yHG4"
      },
      "source": [
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* perform sentiment classification from movie reviews, using a Recurrent Neural Network (RNN)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvDJsz_mnH9j",
        "cellView": "form"
      },
      "source": [
        "#@title Experiment Walkthrough Video\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<video width=\"850\" height=\"480\" controls>\n",
        "  <source src=\"https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/movie_sentiment_analysis.mp4\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox5WyF0y4dMz"
      },
      "source": [
        "## Recurrent neural network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7znelX-BRG1"
      },
      "source": [
        "RNN is a type of neural network that is proven to work well with sequence data. Since text is actually a sequence of words, a recurrent neural network is an automatic choice to solve text-related problems. Here, we will use an LSTM (Long Short Term Memory network) which is a variant of RNN, to solve a movie reviews based sentiment classification problem. \n",
        "\n",
        "An LSTM unit consists of a cell, an input gate, an output gate and a forget gate. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell.\n",
        "\n",
        "LSTM networks are well-suited to classification based on time series data and deal well with the exploding and vanishing gradient problems that can be encountered when training traditional RNNs\n",
        "\n",
        "<img style=\"-webkit-user-select: none;margin: auto;\" src=\"https://miro.medium.com/max/1302/1*yr0820z7YNRcDCWGisLC4g.png\" width=\"450\" height=\"250\">\n",
        "\n",
        "\n",
        "<img style=\"-webkit-user-select: none;margin: auto;\" src=\"https://miro.medium.com/max/1276/1*mvxPFvnDqj2jJrsjevD41A.png\" width=\"450\" height=\"250\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25xeb09mMs0B"
      },
      "source": [
        "## Dataset Description\n",
        "\n",
        "The IMDB dataset from [stanford](http://ai.stanford.edu/~amaas/data/sentiment/) has around 50K movie reviews with the following attributes:\n",
        "* **review:** review of any movie\n",
        "* **sentiment:** positive or negative sentiment value\n",
        "\n",
        "The dataset contains equal number of positive and negative sentiment reviews\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3y2Exi10krJ"
      },
      "source": [
        "### Setup Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPV17Huq0nMm"
      },
      "source": [
        "#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2216842\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TabFxc2D0o1C"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"9959488784\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ChfY8GTH3SB",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook= \"U4W23_56_Movie_Sentiment_Analysis_C\" #name of the notebook\n",
        "def setup():\n",
        "    ipython.magic(\"sx wget -qq https://cdn.talentsprint.com/aiml/Experiment_related_data/IMDB_Dataset.csv\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print (\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "    \n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None   \n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional: \n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional  \n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "  \n",
        "  \n",
        "def getWalkthrough():\n",
        "  try:\n",
        "    if not Walkthrough:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Walkthrough\n",
        "  except NameError:\n",
        "    print (\"Please answer Walkthrough Question\")\n",
        "    return None\n",
        "  \n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup() \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN9xA1xMwIq0"
      },
      "source": [
        "### Importing required packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "MGvbTQ4x8ElJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdz-3IanrBiU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from numpy import array\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdT0aESgsVPU"
      },
      "source": [
        "### Dataset analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAzdHqulsRbv"
      },
      "source": [
        "movie_reviews = pd.read_csv(\"IMDB_Dataset.csv\")\n",
        "\n",
        "movie_reviews.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJcLZO2aN_kl"
      },
      "source": [
        "print(movie_reviews.shape)\n",
        "movie_reviews.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol2PIDSMtCwN"
      },
      "source": [
        "# Let us view one of the reviews\n",
        "movie_reviews[\"review\"][5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMIU5YtCv0k8"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "Remove html tags, punctuations, special characters etc. from the review text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI7nx3eFuLGD"
      },
      "source": [
        "# Data Preprocessing \n",
        "def preprocess_text(sen):\n",
        "    # PRE-PROCESS A GIVEN REVIEW\n",
        "    sen = re.sub('<.*?>', ' ', sen) # remove html tag\n",
        "    sen = re.sub('[^a-zA-Z]', ' ', sen)    # remove non alphabet\n",
        "    sen = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sen)    # remove Single characters\n",
        "    sen = re.sub(r'\\s+', ' ', sen)     # remove multiple spaces\n",
        "    sen = sen.lower() # lower case\n",
        "    return sen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjzvZSmwvO5O"
      },
      "source": [
        "# Store the preprocessed reviews in a new list\n",
        "X = []\n",
        "sentences = list(movie_reviews['review'])\n",
        "for sen in sentences:\n",
        "    X.append(preprocess_text(sen))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viX5aijFhlGf"
      },
      "source": [
        "print(X[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-kFMtmcv6as"
      },
      "source": [
        "# Convert labels to integers\n",
        "y = movie_reviews['sentiment']\n",
        "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-KenTlzwN5x"
      },
      "source": [
        "### Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLuY71VzwK1A"
      },
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "print('Train Set',len(X_train))\n",
        "print('Test Set',len(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQjh4D4eUjWP"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6W_D9WnwiR5"
      },
      "source": [
        "### Prepare the Embedding Layer\n",
        "\n",
        "The embedding layer converts our textual data into a dense vector representation and is used as the first layer for the deep learning models in Keras\n",
        "\n",
        "Steps:\n",
        "\n",
        "1. Tokenization \n",
        "\n",
        "2. Padding\n",
        "\n",
        "3. Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA-C8sYnwyrR"
      },
      "source": [
        "# Tokenizer class from the keras.preprocessing.text module creates a word-to-index integer dictionary\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp6sMPAvgU0C"
      },
      "source": [
        "print(np.asarray(X_train).shape)\n",
        "print(np.asarray(X_test).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7iUq1nGyOzx"
      },
      "source": [
        "The X_train set contains 40,000 lists of integers, each list corresponding to the sentences in a review. Set the maximum length of each list to 100 and add 0 padding to those lists that have a length < 100, until they reach a length of 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPEFSkxZxyRJ"
      },
      "source": [
        "# Perform padding on both train and test set\n",
        "max_length = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_length, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_length, padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pakh5BOKWKgA"
      },
      "source": [
        "print('Encoded X Train\\n', X_train, '\\n')\n",
        "print('Encoded X Test\\n', X_test, '\\n')\n",
        "print('Maximum review length: ', max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6dm4lLnz_TE"
      },
      "source": [
        "### Build LSTM Model for text classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaYKsRLi3Q0F"
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Embedding, LSTM\n",
        "from tensorflow.python.keras.layers.embeddings import Embedding\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "print('Build model...')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(5000, EMBEDDING_DIM, input_length = max_length))\n",
        "model.add(LSTM(units=32,  dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "print('Summary of the built model...')\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1yM4QUJ370N"
      },
      "source": [
        "### Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBo01v6A4KPL"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=2, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-eeqc306cjK"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZoUVfwn6e13"
      },
      "source": [
        "print('Testing...')\n",
        "y_test = np.array(y_test)\n",
        "loss, accuracy = model.evaluate(X_test, y_test, batch_size=128)\n",
        "\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)\n",
        "print(\"Accuracy: {0:.2%}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0ZC_I9h6xTd"
      },
      "source": [
        "# Let us test some  samples\n",
        "test_sample_1 = \"This movie is fantastic! I really like it because it is so good!\"\n",
        "test_sample_2 = \"Good movie!\"\n",
        "test_sample_3 = \"Maybe I like this movie.\"\n",
        "test_sample_4 = \"Not to my taste, will skip and watch another movie\"\n",
        "test_sample_5 = \"if you like action, then this movie might be good for you.\"\n",
        "test_sample_6 = \"Bad movie!\"\n",
        "test_sample_7 = \"Not a good movie!\"\n",
        "test_sample_8 = \"This movie really sucks! Can I get my money back please?\"\n",
        "test_samples = [test_sample_1, test_sample_2, test_sample_3, test_sample_4, test_sample_5, test_sample_6, test_sample_7, test_sample_8]\n",
        "\n",
        "for each in test_samples:\n",
        "  filtered = [preprocess_text(each)]\n",
        "  tokenize_words = tokenizer.texts_to_sequences(filtered)\n",
        "  tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\n",
        "  result = model.predict(tokenize_words)\n",
        "  if result >= 0.7:\n",
        "      print('positive == ',each)\n",
        "  else:\n",
        "      print('negative == ',each)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giNdCc9at8-1"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMJFxr5YskFs",
        "cellView": "form"
      },
      "source": [
        "#@title State True or False: 'model.fit' function is used to train a Keras Sequential model\n",
        "Answer = \"TRUE\" #@param [\"\",\"TRUE\", \"FALSE\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good and Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"Everything is good\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r35isHfTVGKc"
      },
      "source": [
        "#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Walkthrough = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "FzAZHt1zw-Y-"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}